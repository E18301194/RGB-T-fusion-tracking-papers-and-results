# RGB-T fusion tracking：papers，datasets & results
This this the webpage which lists the papers, datasets and results in the field of RGB-T fusion tracking.

## Papers

### Recommendations
- Xingchen Zhang, Ping Ye, Henry Leung, Ke Gong, Gang Xiao.  
  Object Fusion Tracking Based on Visible and Infrared Images: A Comprehensive Review. Information Fusion, 2020.
  
### 2020


### 2019
- Xiangyuan Lan, Mang Ye, Rui Shan, Bineng Zhong, Deepak Kumar Jain, Huiyu Zhou  
	“Online non-negative multi-modality feature template learning for RGB-assisted infrared tracking”. IEEE Access, 2019. [[paper][1]]
- Chengwei Luo, Bin Sun, Ke Yang, Taoran Lu, Wei-Chang Yeh.  
	  “Thermal infrared and visible sequences fusion tracking based on a hybrid tracking framework with adaptive weighting scheme”. Infrared Physics & Technology, 2019. [[paper][2]]
- Sulan Zhai, Pengpeng Shao, Xinyan Liang, Xin Wang.  
	"Fast RGB-T Tracking via Cross-Modal Correlation Filters." Neurocomputing, 2019.[[paper][3]]
- Xiangyuan Lan, Mang Ye, Rui Shao, Bineng Zhong, Pong C.Yuen, Huiyu Zhou.  
	  "Learning Modality-Consistency Feature Templates: A Robust RGB-Infrared Tracking System."IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS 2019.[[paper][4]]
- Chenglong Li, Chengli Zhu, Jian Zhang, Bin Luo, Xiaohao Wu, and Jin Tang.  
	  "Learning Local-Global Multi-Graph Descriptors for RGB-T Object Tracking". IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT), 2019.[[paper][5]]
- Xiangyuan Lan, Mang Ye, Shengping Zhang, Huiyu Zhou, Pong C. Yuen.  
	  "Modality-correlation-aware sparse representation for RGB-infrared object tracking".Pattern Recognition Letters, 2019 ([paper][6])
- Rui Yang, Yabin Zhu, Xiao Wang, Chenglong Li \*, and Jin Tang.  
	  “Learning Target-oriented Dual Attention for Robust RGB-T Tracking”. IEEE International Conference on Image Processing (ICIP), 2019.

### 2018

- Keyan Ren, Xiao Zhang, Yu Han, Yibin Hou.  
	   "Robust night target tracking via infrared and visible video fusion". Applications of Digital Image Processing, 2018. (**asynchronous VI and IR videos**)[[paper][7]]
- Chenglong Li, Xiaohao Wu, Nan Zhao, Xiaochun Cao, and Jin Tang.  
	  "Fusing Two-Stream Convolutional Neural Networks for RGB-T Object Tracking". Neurocomputing (NEUCOM), 281: 78-85, 2018.[[paper][8]]
- Chenglong Li, Chengli Zhu, Shaofei Zheng, Bin Luo, and Jin Tang.  
	  "Two-Stage Modality-Graphs Regularized Manifold Ranking for RGB-T Tracking". Signal Processing: Image Communication (SPIC), 68: 207-217, 2018. [[paper][9]]
- Meng Ding, Yao Yuheng, Li Wei, Yunfeng Cao.  
	  "Visual tracking using Locality-constrained Linear Coding and saliency map for visible light and infrared image sequences". Signal Processing: Image Communication, 2018.([paper][11])
- Xingming Zhang, Xuehan Zhang, Xuedan Du, Xiangming Zhou, Jun Yin.  
	 "Learning Multi-domain Convolutional Network for RGB-T Visual Tracking." CISP-BMEI 2018.
- Chenglong Li, Chengli Zhu, Yan Huang, Jin Tang, Liang Wang.  
	   "Cross-Modal Ranking with Soft Consistency and Noisy Labels for Robust RGB-T Tracking." ECCV 2018.  
- Xiangyuan Lan, Mang Ye, Shengping Zhang, Pong C. Yuen.  
	   "Robust Collaborative Discriminative Learning for RGB-Infrared Tracking". AAAI 2018.
- Yulong Wang, Chenglong Li, and Jin Tang.  
	“Learning Soft-Consistent Correlation Filters for RGB-T Object Tracking”. PRCV 2018.
- Ningwen Xu, Gang Xiao, Xingchen Zhang, Durga Prasad Bavirisetti.  
	"Relative Object Tracking Algorithm Based on Convolutional Neural Network for Visible and Infrared Video Sequences". 4th International Conference on Virtual Reality, 2018
- Ningwen Xu, Gang Xiao, Fang He, Xingchen Zhang, Durga Prasad Bavirisetti.  
	"Object Tracking via Deep Multi-View Compressive Model for Visible and Infrared Sequences". Fusion 2018.
- Chengwei Luo, Bin Sun, Qiao Deng, Zihao Wang, Dengwei Wang.  
	    "Comparison of Different Level Fusion Schemes for Infrared-Visible Object Tracking: An Experimental Survey". 2018 2nd International Conference on Robotics and Automation Sciences.
- K. Senthil Kumar1, G. Kavitha, R. Subramanian, G. Ramesh.  
	    "Visual and Thermal Image Fusion of UAV Based Target Tracking". Intech open, 2018.

### 2017

- Chenglong Li, Xiang Sun, Xiao Wang, Lei Zhang, and Jin Tang.  
	  "Grayscale-thermal Object Tracking via Multi-task Laplacian Sparse Representation". IEEE Transactions on Systems, Man, and Cybernetics: Systems (T-SMCS), 47(4): 673-681, 2017.[[paper][10]]
- Chenglong Li, Nan Zhao, Yijuan Lu, Chengli Zhu, and Jin Tang.  
	   "Weighted Sparse Representation Regularized Graph Learning for RGB-T Object Tracking". ACM International Conference on Multimedia (ACM MM), 2017.

### 2016

- Chenglong Li, Hui Cheng, Shiyi Hu, Xiaobai Liu, Jin Tang, Liang Lin.  
	    “Learning Collaborative Sparse Representation for Grayscale-Thermal Tracking”,  IEEE Transactions on Image Processing (T-IP), 25(12): 5743-5756, 2016. [[paper][12]]
- Xiao Yun, Zhongliang Jing, Bo Jin.
	"Visible and infrared tracking based on multi-view multi-kernel fusion model". Optical Review, 2016.([paper][13])
- Xiao YUN, Zhongliang JING, Gang XIAO, Bo JIN, Canlong ZHANG.  
	 "A compressive tracking based on time-space Kalman fusion model". Science China Information Sciences, 2016.([paper][14])
- Supriya Mangale, Madhuri Khambete.  
	 "Camouflaged target detection and tracking using thermal infrared and visible spectrum imaging". Advances in Intelligent Systems and Computing, 2016.([paper][15])
- Chenglong Li, Shiyi Hu, Sihan Gao, and Jin Tang.  
	   "Real-time Grayscale-thermal Tracking  via Laplacian Sparse Representation". International Conference on Multimedia Modelling (MMM), Miami, 2016.

### Before 2016

- Alex Lipchen Chan, Stephen R. Schnelle.  
	 "Fusing concurrent visible and infrared videos for improved tracking performance". Optical Engineering, 2013.([paper][16])
- Huaping Liu, Fuchun Sun.  
	 "Fusion tracking in color and infrared images using joint sparse representation". Science China Information Sciences, 2012.([paper][17])
- Alex Lipchen Chan, Stephen R. Schnelle.  
	 "Target tracking using concurrent visible and infrared imageries". SPIE, 2012.([paper][18])
- Erhan Gundogdu, Huseyin Ozkan, H. Seckin Demir, Hamza Ergezer, Erdem Akag¨und¨uz, S. Kubilay Pakin.  
	 "Comparison of infrared and visible imagery for object tracking: Toward trackers with superior IR performance". CVPR 2015.
- Stephen R. Schnelle, Alex Lipchen Chan.  
	 "Enhanced target tracking through infrared-visible image fusion". Fusion 2011.
- Huaping Liu, Fuchun Sun.  
- "Fusion tracking in color and infrared images using sequential belief propagation". Proceedings - IEEE International Conference on Robotics and Automation, 2008.


### Multispectral person detection (may give some idea to fusion tracking)
- Daniel K¨onig, Michael Adam, Christian Jarvers, Georg Layher, Heiko Neumann, and Michael Teutsch.  
	 "Fully Convolutional Region Proposal Networks for Multispectral Person Detection". CVPR 2017.


## Datasets and benchmark
- **GTOT**
	- Paper: Chenglong Li, Hui Cheng, Shiyi Hu, Xiaobai Liu, Jin Tang, Liang Lin.  
		“Learning Collaborative Sparse Representation for Grayscale-Thermal Tracking”,  IEEE Transactions on Image Processing (T-IP), 25(12): 5743-5756, 2016. [[paper][19]]
	- Download Link [[Google drive][20]] [[Baidu Cloud][21]]

- **RGBT210**
	- Paper: Chenglong Li, Nan Zhao, Yijuan Lu, Chenglin  Zhu, Jin Tang.  
		“Weighted Sparse Representation Regularized Graph Learning for RGB-T Object Tracking”, ACM International Conference on Multimedia (ACM MM), 2017. [[paper][24]]
	- Download Link [[Google drive][25]][[Baidu Cloud][26]]

- **RGBT234**
	- Paper: Chenglong Li, Xinyan Liang, Yijuan Lu, Nan Zhao, and Jin Tang.  
		“RGB-T Object Tracking:Benchmark and Baseline”, ArXiv, 2018. Submitted to Pattern Recognition (PR), 2019. [[paper][28]][[project][29]]
	- Download Link [[Google drive][30]]

## Results
### GTOT
	Name       | PR   | SR   | Year | Author     |  Type    | FPS |
	FANet      | 88.5 | 69.8 | 2018 | Li et al.  | DL-based | 1.3 |
	SCCF       | 85   | 68.1 | 2018 | Li et al.  | CF-based | 50  |
	LGMG       | 82.9 | 65.5 | 2018 | Li et al.  |          |  7  |
	Cross-modal| 82.7 | 64.3 | 2018 | Li et al.  |          |  8  |
	Fast RGB-T | 77   | 63.2 | 2019 | Zhai et al.| CF-based | 227 |
	Weighted   | 85.12| 62.8 | 2017 | Li et al.  |          |  5  |
	Fusing two | 85.2 | 62.6 | 2018 | Li et al.  | DL-based | 15  |
	Two stage  | 84.2 | 62.2 | 2018 | Li et al.  |          | 7   |
	CSR        | 75   | 62   | 2016 | Li et al.  |          |     |

### RGBT210
	Name       | PR   | SR   | Year | Author     |  Type    | FPS |
	LGMG       | 71.1 | 46.8 | 2018 | Li et al.  |          |  7  |
	Cross-modal| 69.4 | 46.3 | 2018 | Li et al.  |          |  8  | 
	SiamFT     | 65.0 | 44.3 | 2019 |Zhang et al.| DL-bsed  | 25+ |
	Weighted   | 67.5 | 43.0 | 2017 | Li et al.  |          |  5  |  
	Fast RGB-T | 52.9 | 36.6 | 2019 | Zhai et al.| CF-based | 227 |
 
 
### RGBT234
	Name         | PR   | SR   | Year |Author       |  Type    | FPS |
	DAPNet       | 76.6 | 53.7 | 2019 | Li et al.   | DL-based |
	FANet        | 76.4 | 53.2 | 2018 | Li et al.   | DL-based | 1.3 |
	SGT          | 72.0 | 47.2 | 2018 | Li et al.   |          | 
	SiamFT       | 65.9 | 44.8 | 2019 | Zhang et al.| DL-based | 25+ |
	SiamFC_RGT   | 61.0 | 42.8 | 2019 | Zhang et al.| DL-based |     |  
	Multi-domain | 61.7 | 38.7 | 2018 | Zhang et al.| DL-based |     |


[1]:	https://ieeexplore.ieee.org/document/8713854
[2]:	https://www.sciencedirect.com/science/article/pii/S1350449519300258
[3]:	https://www.sciencedirect.com/science/article/pii/S0925231219300347
[4]:	https://ieeexplore.ieee.org/document/8643077
[5]:	https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8485393
[6]:	https://www.sciencedirect.com/science/article/pii/S0167865518307633
[7]:	https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10752/1075206/Robust-night-target-tracking-via-infrared-and-visible-video-fusion/10.1117/12.2320450.full?SSO=1
[8]:	https://www.sciencedirect.com/science/article/pii/S0925231217318271
[9]:	https://www.sciencedirect.com/science/article/pii/S0923596518304892
[10]:	https://link.springer.com/chapter/10.1007%2F978-3-319-27674-8_6
[11]:	https://www.sciencedirect.com/science/article/pii/S0923596518302510
[12]:	https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7577747
[13]:	https://link.springer.com/article/10.1007/s10043-015-0175-5
[14]:	https://link.springer.com/article/10.1007/s11432-015-5356-0
[15]:	https://link.springer.com/chapter/10.1007/978-3-319-47952-1_15
[16]:	https://www.spiedigitallibrary.org/journals/Optical-Engineering/volume-52/issue-1/017004/Fusing-concurrent-visible-and-infrared-videos-for-improved-tracking-performance/10.1117/1.OE.52.1.017004.full
[17]:	https://link.springer.com/article/10.1007/s11432-011-4536-9
[18]:	https://www.spiedigitallibrary.org/conference-proceedings-of-spie/8392/83920P/Target-tracking-using-concurrent-visible-and-infrared-imageries/10.1117/12.918373.full
[19]:	https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7577747
[20]:	https://docs.google.com/uc?id=0B-Z6TyBF2ceIZ0c1anVhaHQ3MFk&export=download
[21]:	https://pan.baidu.com/s/1QNidEo-HepRaS6OIZr7-Cw
[22]:	https://www.sciencedirect.com/science/article/pii/S0925231217318271
[23]:	https://www.sciencedirect.com/science/article/pii/S0925231219300347
[24]:	https://dl.acm.org/citation.cfm?id=3123289
[25]:	https://drive.google.com/file/d/0B3i2rdXLNbdUTkhsLVRwcTBTMlU/view
[26]:	https://pan.baidu.com/s/1qXDAq0O#list/path=%2F
[27]:	https://www.sciencedirect.com/science/article/pii/S0925231219300347
[28]:	https://arxiv.org/pdf/1805.08982.pdf
[29]:	https://sites.google.com/view/ahutracking001/
[30]:	(https://drive.google.com/open?id=1ouNEptXOgRop4U7zYMK9zAp57SZ2XCNL)
[31]:	http://cs.ahu.edu.cn/7d/82/c11202a163202/page.htm